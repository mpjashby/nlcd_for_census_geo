---
title: "NLCD data processing"
output: html_notebook
---


NLCD data consists of points every 30 metres coded to one of [20 land-cover
categories](https://www.mrlc.gov/nlcd11_leg.php). This script works by:

  * downloading census block outlines for each state,
  * counting the number of points of each type in each census block,
  * merging these counts into a single table for each state,
  * aggregating these counts for block groups and tracts.


# Load packages

All packages needed in this project are loaded here, so that they can be loaded 
quickly when opening the project.

```{r}
# raster processing functions
# note this should be loaded before tidyverse because otherwise raster::select()
# masks dplyr::select()
library("raster")
# data manipulation
library("tidyverse")
library("lubridate")
# downloading files
library("httr")
# spatial functions for vector objects that are compatible with raster functions
library("sp")
# spatial functions for vector objects that are compatible with tigris
library("sf")
# download census outlines
library("tigris")
# parellel processing
library("parallel")
```


# Get NLCD data

[National Land Cover Database](https://www.mrlc.gov/) (NLCD) data are available 
as a single zipped raster for the whole continental United States. 

```{r}
# download file
GET("http://www.landfire.gov/bulk/downloadfile.php?TYPE=nlcd2011&FNAME=nlcd_2011_landcover_2011_edition_2014_10_10.zip", write_disk("original_data/nlcd_data.zip"), progress())

# unzip files on disk
unzip("original_data/nlcd_data.zip", exdir = "original_data")

# move unzipped files into correct folder
list.files("original_data/nlcd_2011_landcover_2011_edition_2014_10_10/", 
           pattern = "\\.", full.names = TRUE, include.dirs = FALSE) %>% 
  file.copy("original_data")
  # lapply(function (x) {
  #   file.rename()
  # })

# remove directory that is no longer needed
unlink("original_data/nlcd_2011_landcover_2011_edition_2014_10_10", 
       recursive = TRUE)
```

Having downloaded the raster to a file we can now load it. Note that `raster()`
does not load the entire raster, instead loading parts as needed later on.

```{r}
# load raster
nlcd_raster <- raster("original_data/nlcd_2011_landcover_2011_edition_2014_10_10.img")
```


The NLCD categories are:

```{r}
nlcd_types <- list(
  "11" = "Open Water",
  "12" = "Perennial Ice/Snow",
  "21" = "Developed, Open Space",
  "22" = "Developed, Low Intensity",
  "23" = "Developed, Medium Intensity",
  "24" = "Developed, High Intensity",
  "31" = "Barren Land (Rock/Sand/Clay)",
  "41" = "Deciduous Forest",
  "42" = "Evergreen Forest",
  "43" = "Mixed Forest",
  "51" = "Dwarf Scrub",
  "52" = "Shrub/Scrub",
  "71" = "Grassland/Herbaceous",
  "72" = "Sedge/Herbaceous",
  "73" = "Lichens",
  "74" = "Moss",
  "81" = "Pasture/Hay",
  "82" = "Cultivated Crops",
  "90" = "Woody Wetlands",
  "95" = "Emergent Herbaceous Wetlands"
)
```


# Count NLCD points in each census block

We will use the `tigris` package to get census boundaries and the `getValues()`
function from the `raster` package to count the number of points in each raster.

State FIPS codes are:

```{r}
data("fips_codes")
state_codes <- fips_codes %>% 
	as_tibble() %>% 
	rename(code = state_code) %>% 
	group_by(code) %>% 
	summarize(name = first(state_name), abbr = first(state)) %>% 
	filter(as.numeric(code) < 60)
rm(fips_codes)

# FIPS codes for states to be processed - the 48 contiguous states plus DC
states_to_process <- state_codes %>% 
	filter(!name %in% c("Alaska", "Hawaii")) %>% 
	{ as.character(.$code) }
```

`raster` does not yet play very nicely with `sf`, so we need to use `sp` objects
for the block outlines.

```{r}
# set cache directory for tigris files
tigris_cache_dir("original_data")
readRenviron('~/.Renviron')

for (x in states_to_process) {
	
	tryCatch({
		
		# download state outline (in SF format)
		print(paste("Downloading outline of state", x))
		state_outline <- states(class = "sf") %>% 
			filter(STATEFP == x) %>% 
			st_transform(proj4string(nlcd_raster)) %>% 
			as("Spatial")
		
		# create a raster for this state
		print(paste("Creating raster for state", x))
		state_raster <- crop(nlcd_raster, extent(state_outline))
		
		# download census blocks (in SF format)
		print(paste("Downloading block outlines for state", x))
		block_outlines <- blocks(state = x) %>% 
			spTransform(proj4string(nlcd_raster))
		
		# count how many blocks in the state
		blocks_in_state <- nrow(block_outlines)
		
	}, 
	warning = function (w) {
		print(paste("Warning:", w))
	},
	error = function (e) {
		print(paste("Error:", e))
		next
	})
  
  # initialise cluster
  cluster <- makeCluster(detectCores() - 1)
	
	# note start time
	time_start <- Sys.time()
	
	# specify variables and libraries that should be available within the parallel lapply loop
	clusterExport(cluster, c("state_raster", "block_outlines", "blocks_in_state", "time_start"))

	# loop over blocks in the state	
	print(paste("Processing", format(blocks_in_state, big.mark = ","), 
							"blocks ..."))
	block_cell_counts <- tryCatch({
	  parLapplyLB(cluster, 1:blocks_in_state, function (y) {
	    
	  # load packages inside parallel loop
	  library("raster")
	  library("tidyverse")
	  library("lubridate")
	  library("sp")
	  library("sf")
	  library("tigris")
	       
	  # get outline of the current block 
		block_outline <- block_outlines[y, ]
		
		# create raster for just cells within current block
		local_nlcd <- raster::crop(state_raster, raster::extent(block_outline))
		
		# extract values from local raster
		block_cell_count <- raster::rasterize(block_outline, local_nlcd, mask = TRUE) %>%
			raster::getValues() %>%
			tibble::as_tibble() %>%
			dplyr::filter(!is.na(value)) %>%
			dplyr::group_by(value) %>%
			dplyr::summarise(count = n()) %>%
			dplyr::mutate(
				block = as.character(as.data.frame(block_outlines[y, "GEOID10"]))
			) %>%
			dplyr::select(block, value, count)
		
		# estimate how long progress will take
		if (y %in% c(10, 100)) {
			print(paste(
				"  after", y, "iterations, it appears processing",
				format(blocks_in_state, big.mark = ","),
				"blocks will take approximately another",
				round(lubridate::seconds_to_period(
					((as.numeric(Sys.time()) - as.numeric(time_start)) / y) * (blocks_in_state - y)
				))
			))
		}

		# print occasional update
		if (y %% floor(blocks_in_state / 10) == 0) {
			print(paste(
				"  processed", format(y, big.mark = ","), "records -",
				sprintf("%.0f%%", (y / blocks_in_state) * 100), "of total,",
				round(lubridate::seconds_to_period(
					((as.numeric(Sys.time()) - as.numeric(time_start)) / y) * (blocks_in_state - y)
				)), "to go"
			))
		}
		
		# return block counts
		block_cell_count
		
	})},
	error = function (e) {
		print(paste("Error:", e))
	})
	
	# stop cluster
	stopCluster(cluster)
	
	tryCatch({
		
		print(paste("Processed data for state", x, "in", 
								round(seconds_to_period(
									as.numeric(Sys.time()) - as.numeric(time_start)
								))))
		
		# combine tibbles
		print("Combining cell counts")
		block_cell_counts <- block_cell_counts %>% reduce(rbind)
		
		# save state data to a file
		cat("Saving data to file\n\n")
		write_csv(block_cell_counts, path = paste0("analysis_data/state_", x, "_block_counts.csv"), na = "")

		# return block counts
		block_cell_counts
		
	}, 
	warning = function (w) {
		print(paste("Warning:", w))
	},
	error = function (e) {
		print(paste("Error:", e))
		next
	})
	
}
```


# Manipulate format of count data

```{r}
# This function converts counts of raster cells into the proportion of raster
# cells in each census area that are of a particular type. It expects a tibble
# with one variable called count_total at at least one other variable with a
# name starting count_
count_to_prop <- function (x) {
	
	if (!is.tibble(x)) {
		stop("x must be a tibble")
	}
	if (!"count_total" %in% names(x)) {
		stop("x must include a variable called 'count_total'")
	}
	if (sum(str_detect(names(x), "count_")) < 2) {
		stop("x must contain at least two variables with names beginning 'count_'")
	}

	x %>% 
		rename(cell_count = count_total) %>%
		mutate_at(vars(starts_with("count_")),
							funs(prop = round(. / cell_count, digits = 4))) %>%
		rename_at(vars(ends_with("_prop")),
							funs(paste("prop",
												 gsub("_", "", str_extract(., "_.+_")),
												 sep = "_"))) %>%
		select(-starts_with("count_"))

}

# This function writes a tibble of raster cell counts to a gzipped CSV file,
# first converting the counts to proportions if required
write_census_csv <- function(data, state, level, type) {
	
	if (!is.tibble(data)) {
		stop("data must be a tibble")
	}
	if (!is.character(state)) {
		stop("state must be a character")
	}
	if (str_length(state) != 2) {
		stop("state must contain two characters")
	}
	if (!is.character(level)) {
		stop("level must be a character")
	}
	if (!level %in% c("block", "blockgroup", "tract")) {
		stop("level must be one of 'block', 'blockgroup' or 'tract'")
	}
	if (!is.character(type)) {
		stop("type must be a character")
	}
	if (!type %in% c("count", "prop")) {
		stop("level must be one of 'count' or 'prop'")
	}
	
	if (type == "prop") {
		data <- data %>% count_to_prop()
	}
	
	write.csv(data, file = gzfile(paste0("./analysis_data/nlcd_", level, "_", 
																			 type, "_", state, ".csv.gz")),
						row.names = FALSE)

	return(data)
		
}

dir("./analysis_data", pattern = "*_block_counts.csv$", full.names = TRUE) %>% 
	head(1) %>% 
	map(function (x) {
		
		# this code uses base::write.csv() rather than readr::write_csv() because 
		# there is a bug affecting the writing of some numbers â€” see
		# https://github.com/tidyverse/readr/issues/845
		# a useful side effect of this is that the base function quotes the block
		# variable, preventing it being parsed as a number when the file is read,
		# although this does increase the file size
		
		# print update
		print(paste("Started processing file", x, "at", now()))
		
		# convert from long to wide, so that each row is a census block, and sum
		# the number of points in each block
		block_counts <- read_csv(x, col_types = cols(
			block = col_character(),
			.default = col_integer()
		)) %>% 
			rename(points = count, count = value) %>% 
			spread(count, points, sep = "_", fill = 0) %>% 
			mutate(count_total = select_if(., is.numeric) %>% rowSums())
		
		# find state code
		this_state <- str_sub(block_counts$block[1], 0, 2)

		# create CSVs for blocks
		block_counts %>%
			write_census_csv(this_state, "block", "count") %>% 
			write_census_csv(this_state, "block", "prop")
			# write.csv(paste0("./analysis_data/nlcd_block_count_", this_state, ".csv"),
			# 					row.names = FALSE)
		# block_counts %>%
		# 	count_to_prop() %>%
		# 	write.csv(paste0("./analysis_data/nlcd_block_prop_", this_state, ".csv"),
		# 						row.names = FALSE)
		
		# aggregate to block groups
		bg_counts <- block_counts %>% 
			mutate(blockgroup = str_sub(block, 0, 12)) %>% 
			group_by(blockgroup) %>% 
			summarise_if(is.numeric, sum) %>% 
			write_census_csv(this_state, "blockgroup", "count") %>% 
			write_census_csv(this_state, "blockgroup", "prop")

		# create CSVs for block groups
		# bg_counts %>% 
		# 	write.csv(paste0("./analysis_data/nlcd_blockgroup_count_", 
		# 									 this_state, ".csv"),
		# 						row.names = FALSE)
		# bg_counts %>% 
		# 	rename(cell_count = count_total) %>%
		# 	count_to_prop() %>% 
		# 	write.csv(paste0("./analysis_data/nlcd_blockgroup_prop_", 
		# 									 this_state, ".csv"), 
		# 						row.names = FALSE)
		
		# aggregate to tracts
		tract_counts <- block_counts %>%
			mutate(tract = str_sub(block, 0, 11)) %>%
			group_by(tract) %>%
			summarise_if(is.numeric, sum) %>% 
			write_census_csv(this_state, "tract", "count") %>% 
			write_census_csv(this_state, "tract", "prop")

		# create CSVs for tracts
		# tract_counts %>% 
		# 	write.csv(paste0("./analysis_data/nlcd_tract_count_", this_state, ".csv"),
		# 						row.names = FALSE)
		# tract_counts %>% 
		# 	rename(cell_count = count_total) %>%
		# 	count_to_prop() %>% 
		# 	write.csv(paste0("./analysis_data/nlcd_tract_prop_", this_state, ".csv"), 
		# 						row.names = FALSE)
						
		# don't return the huge data frame
		FALSE

	}) %>% invisible()
```

